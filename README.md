# Inline-ML

**Machine Learning-Guided Inlining for LLVM**

Inline-ML is a research prototype that applies machine learning to LLVM IR inlining decisions. Originally created for a capstone project, it now serves as a standalone CLI tool that explores data-driven compiler optimization. The system learns from real-world C codebases to predict when inlining should occur, using interpretable models like XGBoost.

---

## âœ¨ Features

- **CLI-first Interface** â€“ Streamlined, headless usage suitable for pipelines and research.
- **LLVM IR Feature Extraction** â€“ Uses `llvmcpy` and heuristics to derive useful metadata from IR callsites.
- **Real-world Training Data** â€“ Pulls from diverse, widely-used open-source C projects.
- **Model Transparency** â€“ XGBoost model enables interpretable decisions and feature importance analysis.
- **Extensible Pipeline** â€“ Each stage of data collection, processing, and prediction is modular and hackable.

---

## ğŸ“¦ Requirements

- OS: Windows 10, macOS, or Linux
- Python 3.12+
- Poetry ([Install Guide](https://python-poetry.org/))
- Clang + LLVM in PATH

---

## ğŸš€ Getting Started

1. Clone the repo
2. Install Poetry:
   ```bash
   pip install poetry
   ```
3. Install dependencies:
   ```bash
   poetry install
   ```

4. Run the full pipeline:
   ```bash
   poetry run python pipeline.py
   ```

5. Train the model:
   ```bash
   poetry run python train_model.py
   ```

This will output a trained model as `inline_model.json`.

---

## ğŸ§¬ Dataset Sources

Inline-ML collects training data by scraping permissively licensed C codebases from GitHub. The dataset is automatically generated by compiling source files to LLVM IR, extracting callsite features, and aggregating results for model training. The pipeline is designed to be extensible, making it easy to expand coverage across diverse projects and code styles.

---

## ğŸ“ Outputs

- `data/data.csv`: Generated CSV containing extracted callsite-level features for training the model. **Note:** This file is not included in the repository and must be generated via the pipeline.
- `inline_model.json`: Trained XGBoost model file. **Note:** This file is not included in the repository and is created after running the training step.

---

## ğŸ› ï¸ Future Directions

- Fully-featured CLI replacing GUI
- Improved feature engineering via embeddings or GNNs
- Broader language frontend support (Rust, Swift, etc.)
- LLVM plugin integration